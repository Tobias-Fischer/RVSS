{"cells":[{"cell_type":"markdown","metadata":{"id":"W1KV5maSGtU9"},"source":["# <center> Introduction to Reinforcement Learning</center>"]},{"cell_type":"markdown","metadata":{"id":"KDedkNiYGtU_"},"source":["# 1. Setup"]},{"cell_type":"markdown","metadata":{"id":"96yRlg56GtU_"},"source":["#### Let us first make sure that all the required dependencies are installed"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"U2yWugvjGtU_","executionInfo":{"status":"ok","timestamp":1643770377635,"user_tz":-660,"elapsed":3771,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"a0894d15-ebc0-42a7-b009-86ac52f4cade","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"]}],"source":["import sys\n","!{sys.executable} -m pip install gym"]},{"cell_type":"code","source":["!git clone https://github.com/Tobias-Fischer/RVSS2022.git"],"metadata":{"id":"vwGGniauG9RX","executionInfo":{"status":"ok","timestamp":1643770390260,"user_tz":-660,"elapsed":9148,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"3f76ca14-127f-44e0-8724-0a9ac7f7aeaf","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'RVSS2022'...\n","remote: Enumerating objects: 684, done.\u001b[K\n","remote: Counting objects: 100% (684/684), done.\u001b[K\n","remote: Compressing objects: 100% (551/551), done.\u001b[K\n","remote: Total 684 (delta 379), reused 356 (delta 125), pack-reused 0\u001b[K\n","Receiving objects: 100% (684/684), 39.30 MiB | 11.53 MiB/s, done.\n","Resolving deltas: 100% (379/379), done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"wo1UIMwFGtVA"},"source":["#### Import dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"awbK78G1GtVA","executionInfo":{"status":"ok","timestamp":1643770404673,"user_tz":-660,"elapsed":780,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}}},"outputs":[],"source":["# %matplotlib notebook\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import numpy as np\n","import pickle\n","\n","import sys\n","import os\n","sys.path.insert(0, os.path.abspath('RVSS2022/Reinforcement_Learning/Support'))\n","\n","from gym_simple_gridworlds.envs.grid_env import GridEnv\n","from gym_simple_gridworlds.envs.grid_2dplot import *\n","from gym_simple_gridworlds.helper import *\n","\n","from IPython.core.display import display, HTML, Image"]},{"cell_type":"markdown","metadata":{"id":"wVcq_PYIGtVB"},"source":["# 2. Elements of an MDP (Grid World Example)\n","\n","Recall the grid in which our robot lives\n","\n","![](https://raw.githubusercontent.com/Tobias-Fischer/RVSS2022/main/Reinforcement_Learning/Support/images/GridWorldExample.png)"]},{"cell_type":"markdown","source":["\n","- The states $s \\in \\mathcal{S}$ correspond to locations in the grid. Each location has also a cell index associated to it, e.g., cell index 4 is associated to location (row=1,col=0)\n","- The robot can move up, down, left, or right. Actions correpond to unit increments or decrements in the specified direction.\n","    - Up : (-1,0)\n","    - Down: (1,0)\n","    - Left: (0,-1)\n","    - Right: (0, 1)\n","- Each action is represented by a number. Action (Up) is represented by 0, (Down) by 1, (Left) by 2 and, finally, (Right) by 3. No actions are available at a terminal state\n","\n","We have defined the class ``GridEnv`` to represent our Grid World MDP. **Take a look at the attributes of this class by placing the cursor somewhere on the class' name and hit SHIFT+TAB. If there's a + button at the top of the popup tooltip, this means the documentation spans a few lines, click it to show the full docstring, then scroll up.**"],"metadata":{"id":"gLPvOIGiMbl5"}},{"cell_type":"markdown","metadata":{"id":"w3oqJhvwGtVB"},"source":["## 2.1 Create Environment and Explore its Attributes\n","\n","The noise parameter corresponds to the probability of a change of direction when an action is taken (e.g., going left/right when agent decides to move up/down)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OdO2o41sGtVC","executionInfo":{"status":"ok","timestamp":1643773261423,"user_tz":-660,"elapsed":301,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}}},"outputs":[],"source":["# Create a Grid World instance\n","grid_world = GridEnv(gamma=0.9, noise=0.2, living_reward=-0.04)"]},{"cell_type":"markdown","metadata":{"id":"p4scjuAzGtVC"},"source":["### State and Action Spaces\n","\n","Let's take a look at the state and action spaces of our environment"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ed2JLqb5GtVC","executionInfo":{"status":"ok","timestamp":1643773269768,"user_tz":-660,"elapsed":343,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"312d56e4-5f5a-43e2-b758-9cc87b7cbad3","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Discrete(11)\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","\n","Discrete(4)\n","[0, 1, 2, 3]\n"]}],"source":["# State (or observation) space\n","print(grid_world.observation_space)\n","print(grid_world.get_states())\n","print()\n","\n","# Action space\n","print(grid_world.action_space)\n","print(grid_world.get_actions())"]},{"cell_type":"markdown","metadata":{"id":"4A6gWLd-GtVC"},"source":["### Transition Function\n","\n","Let's take a look at the current state transition function. Some things to keep in mind regarding the transition function:\n","\n","1. Given that $\\mathcal{T}: \\mathcal{S} \\times \\mathcal{A} \\times \\mathcal{S} \\rightarrow \\mathbb{R}$, the ``state_transitions`` attribute of the class ``GridEnv`` corresponds to a 3-Dimensional numpy array of size $11\\times4\\times11$.\n","2. With a noise attribute set to 0.2, at state 5, if the agent chooses to move up, it will end up at:\n","    - state 2 with $80\\%$ probability,\n","    - state 6 with $10\\%$ probability, or\n","    - state 5 with $10\\%$ probability"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"p168neVEGtVC","executionInfo":{"status":"ok","timestamp":1643773319534,"user_tz":-660,"elapsed":304,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"3a66bd15-3095-49b6-ed1a-6cf3d98eb88d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.  0.  0.8 0.  0.  0.1 0.1 0.  0.  0.  0. ]\n"]}],"source":["print(grid_world.state_transitions[5,0])"]},{"cell_type":"markdown","metadata":{"id":"QzE47q6YGtVD"},"source":["### Living Reward and Reward Function\n","\n","Let's now take a quick look at the living reward (i.e., running cost) and reward function $\\mathcal{R}: \\mathcal{S} \\times \\mathcal{A} \\rightarrow \\mathbb{R}$.\n","\n","1. Living reward corresponds to the attribute ``living_rewards`` of the class ``GridEnv`` and is represented as an 1-Dimensional numpy array\n","2. The reward function corresponds to the attribute ``rewards`` of the class ``GridEnv`` and is also represented as a 2-Dimensional numpy array of size $11\\times4$"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"SbHMpqtXGtVD","executionInfo":{"status":"ok","timestamp":1643773365201,"user_tz":-660,"elapsed":471,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"23412683-4d9e-468a-dbd9-71a9727c7169","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Living rewards for all states:\n","[-0.04 -0.04 -0.04  1.   -0.04 -0.04 -1.   -0.04 -0.04 -0.04 -0.04]\n","\n"]}],"source":["# Living rewards\n","print(\"Living rewards for all states:\\n{}\\n\".format(grid_world.immediate_rewards))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j_VKxox2GtVD"},"source":["### Policy\n","\n","Let's see the path and total reward of an agent moving on our grid world according to some random policy\n"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"Xv6VtarzGtVD","executionInfo":{"status":"ok","timestamp":1643785457818,"user_tz":-660,"elapsed":299,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"colab":{"base_uri":"https://localhost:8080/","height":333},"outputId":"e48208b5-bedb-47a5-cac7-a70fa6d90eb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Decoded policy\n"," [[ 1  3  0 -1]\n"," [ 3 -1  3 -1]\n"," [ 3  0  0  1]]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# We randomly pick an action to take in each state\n","# Generate an initial random policy\n","test_policy = define_random_policy(grid_world)\n","encoded_test_policy = encode_policy(grid_world,test_policy)\n","test_policy_matrix = decode_policy(grid_world,encoded_test_policy)\n","\n","\n","# Or, we could specify our own policy\n","#test_policy_matrix = np.array([[3,      3,  3,  -1],\n","#                         [0, np.NaN,  0,  -1],\n","#                          [0,      2,  0,   2]])\n","#encoded_test_policy = encode_policy(grid_world,test_policy_matrix)\n","\n","\n","plot_policy(grid_world,test_policy_matrix)\n","print(\"Decoded policy\\n\", test_policy_matrix)"]},{"cell_type":"markdown","metadata":{"id":"ot4aPblnGtVE"},"source":["Let's now apply this policy and observe the agent's behavior (blue dot in the figure shown below)."]},{"cell_type":"code","execution_count":89,"metadata":{"id":"cf-1PeP7GtVE","executionInfo":{"status":"ok","timestamp":1643785461804,"user_tz":-660,"elapsed":287,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"b73f8fb2-1f31-4509-b886-28202356b872","colab":{"base_uri":"https://localhost:8080/","height":264}},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# Create a Grid World instance\n","grid_world = GridEnv(gamma=0.99, noise=0.2, living_reward=-0.04)\n","s_x, s_y = get_state_to_plot(grid_world)\n","\n","# We can visualize our grid world using the render() function\n","fig, ax = grid_world.render()\n","agent, = ax.plot([], [], 'o', color='b', linewidth=6)\n","reward_text = ax.text(0.02, 0.95, '', transform=ax.transAxes)\n","\n","done = False\n","cumulative_reward = 0\n","grid_world.reset() #can reset to start from a different initial condition\n","cur_state = grid_world.cur_state\n","path_to_plot = []\n","\n","while not done:\n","    _, cur_reward, done, _ = grid_world.step(int(test_policy_matrix[cur_state[0], cur_state[1]]))\n","    cur_state = grid_world.cur_state\n","    n_x, n_y = get_state_to_plot(grid_world)\n","    cumulative_reward += cur_reward\n","    path_to_plot.append([cumulative_reward, n_x, n_y])\n","\n","def init():\n","    agent.set_data(s_x + 0.5, s_y + 0.5)\n","    reward_text.set_text('')\n","    return agent, reward_text\n","\n","def animate(i):\n","    if i < len(path_to_plot):\n","        r, n_x, n_y = path_to_plot[i]\n","        agent.set_data(n_x + 0.5, n_y + 0.5)\n","        reward_text.set_text('Cumulative reward: %.2f' % r)\n","    return agent, reward_text"]},{"cell_type":"code","source":["ani = animation.FuncAnimation(fig, animate, frames=len(path_to_plot), blit=False, interval=500, init_func=init,\n","                              repeat=False)\n","HTML(ani.to_html5_video())"],"metadata":{"id":"FnFtW4CTRNGm","executionInfo":{"status":"ok","timestamp":1643785466390,"user_tz":-660,"elapsed":960,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"292ae608-ad52-42f8-ccf4-2f3fde126ba1","colab":{"base_uri":"https://localhost:8080/","height":309}},"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"288\" height=\"288\" controls autoplay>\n","  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAYTW1kYXQAAAKtBgX//6ncRem9\n","5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n","QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n","eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n","MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n","PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n","b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MyBsb29r\n","YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n","ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n","bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n","aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MiBzY2VuZWN1dD00MCBpbnRyYV9yZWZyZXNo\n","PTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0wLjYwIHFw\n","bWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAADJRliIQA\n","F//+99S3zLLtU2+2C6j3op4mX0N1JQGblsTtOoCtJDa1VEL3fALwAkAv4vXFh4U6AAiN7uhiIXig\n","ZI0J+xFw3PTeTJOqJwI34LszXl2UZ0w25BD3QbMZLnruRuuYIkaf4EPJKZrzmx7vhlamNDmsHtDF\n","XOt31q3rQkEMugkzZq1VIPfBga+hsapY8P2edPfXpfQzlS1WH/uiUpCjT7BXAHHVAdCkavx+RJP5\n","gMBks5JcGKPz/jE97Nu7RLtvNMoBDGQYvVXOfwDnSfHWgKObVA9xUnHaA2MViv47V77MuoXEUdl4\n","ZWbVGy2hRahC/0xM6iPmd3lwCS1Cz53ZL9cpnwu2mVuMP6BQI9aXejGQDpHph2ZY4kN+DxqqTYJV\n","7IcPZGewKBn14PLS9TYzTb/ir1z5pFJnF4CFN4ncvQJ50IiIg1DEPI0xJVXj7BCSY/GTGSCj7C88\n","A49M0IBHIWYTxAUG5zUg6b3kmOyeNqB7HglwLusl4EfepNABNjCHQrYAQjM9D0h74C6Dxd37BSbn\n","IQlpuO3WUOqFmx8Fn1xUfTWmcRt78kHbRq2GCAShVqxFBiwsY2fRv+SnVGdYpm9jKiXmBZZYlciY\n","Mo0zGjTP956aPmh9D+DlpTK3FIH/v6KZhk3qdE9ckK3Oh3d9lH0TW3XzV8UHAjWzwkw1osRg7XpP\n","lARBmv4mfcSsyGmlRA5fEJJF37XGoc3BkQGQuR9d5W5qP9oMoJNchYxU0RfVjY0aopPqAUZuyel9\n","8lGn81lfxmn78UutoQaBZD+HNxFj29pC7fDHnnq8BLXL7YQkBd3d/oMFapTAQSPJ5+h6J/9VBHHv\n","JyUjGLe4PD2UcWD9ZTI0G1O2cIQ+mxmJFADoh198Jmg/JYUhdrGAgFXt99Pn8ywfWcFr18M+qsEE\n","XaA6YrYxoOlnDuAgp1fDMok8QtBqOfntzT2NKQVZTFAHfCiKqVkMbmkkLymIxewdedNlBtMCzNhY\n","ZQVBU/ZFM+APHpgHRfRId60CSuf4BNwwflY6k+G3QTf28yhIvBmunMOZPzBKFtjnXbbZp9WFUXbj\n","Xm6jszN3Z+lc6EA6aPsx27qrXWNP/U8E9jH192hL0M8R1SovJkCmfy6SEwMSqjyv4IraBmpu2nlF\n","GvpA3SZq7P2lrQ9RusB2HanQTTgIeVDoMQZuQknMUbr6D1I1J1XWIDxQ1+jl/VVwBfr33g5t+5XB\n","vD7dEoKYOR9PhmkC66sn5RqjMHYh7IpWCnokDZd0t/CKOSEOgSkqSBgN/q4NfkjJ3/hthXsaaQYO\n","tcfOd0SdK7o0gN/ewlZWvVYB98eGz87m+wfre4pfcdBzCMndVXpF6VRRmmufJMMZeX6r5o+KxPy0\n","r6lTAlzuCzy/r4VAAJlB2RihFJsuj4Av3T668ul27oiLY6KtAdl641p8mvmrtiuntX0sYLUh4a2O\n","v4DfdxmdK/dnwRp7zkEZ8dV4BrXfedYBAYhZBShuBX8cqRmlWChxW6xQk1187F7sSn/2L8c6Vo6M\n","Q3cgHlMhBH2En6UyD/N/eR6l/YbJJv2AjAxGQFnFEHcnq5Mo3455NDEp+czDagKjUK2hC3nzxHeR\n","ATfYHMlNZSsgwTpyzpsK6ePEoWuJIydXzGdA+imhqPKdAPzdydA44j4Z85TW81mCWkiSnXyV6jBv\n","CzP/ACqoternNg0ZfiOWwTsJ+VCHdjzOpOS4mxYCP0hHGiaFYyXmGDZD2ih+VEjaOoBrrXvliF4d\n","+e117XVfyUBlVUrUrgX9jxYpUBviUihGa/GUbvkXW/xRfAnHMXOJh7cUZaWBZ75Go82YvBnuU78j\n","XRxdo/D+2miMvC7EvH95fHgRp5UgEr5udYAvC7mzmkXSfH5LTKjQAGL/4VXxMoXMDxSqLMXC1aKI\n","HtRf/VZHxdtewhq0I7buTLGrGz/XHAE2xPR2KJmG7FfmCIaEDKa+SPA+A3RAXpK+jaYyP9NF9jeI\n","vSIFpYwY5mHkYqwBGmJHqYaVhx/H3WmaWmnxgTLZFIljiqczDajlwXdsbHVg6ZqqK5Kp6996N+34\n","R/OemgjDYpimofstq+7uqn8rXs5Fjf5zpoU5Ve/W5Fdo5h15mVbqxAuUC6aOxqwF6AMKIADXzCN7\n","ULMlovKO9b2Qtq4KXBZlM1nEKKCb96jJ/czBan4tXrx3TBlOMc9lYGzs0yjkWdvXdVQb04wAzalY\n","12jDE4bfsj0iZWQ1zldaFHR8gkyDyKsWTrZfEEArk1sfdvFsReYUZGs4c8PMNC1t5F95ZyFdWkyr\n","SBeG25fEEsgg9AdO0BbzPgXQeSzujW4A03CZZ2dk9jL+gGU1xmEEuL9a5zjVJiL+ynQO/Ur8v4lF\n","Cnf91Ltq8bM4/f/6LgFj0lbHJ+Ep0/YfZX8smV9R638jxIPqDuYDqg1/UvNYAWE/3ZwN4WFwyeIs\n","LIEv7gNleeHC5jb5DjLyfEbhf+FIh6SF7NR/Ne+FtztUyq/7tS2h2nbzP1VdgWN3kYoyaRfAmTha\n","9wQJpB1MHslYguevX/YDUkjSjKslZQ8UI3MtXcxWTZRGNTahIRZSJq44qfFeWKTbV0XJ3et1khB8\n","be5Q2JCsiAhW7Yy1Z69RWZ6/dQmI2UM0agpdRI7Vey1hIRwAUF53ke7YkQgi5oR19n7WCbF97LjD\n","SBWZqIOz8hq9BF5Wga4Nb3czjnbuh0BqnzA3x+UVAVhBcTmLhVECEkkTezUXpkvuviIQ/Noyqxg6\n","TSIVJRwC9eW83e0OE3Fq7EZliiYlgXj4iXEm/ybMQ67Psfw5HEpY3d5cogWxEc3hnSkVWpR1c/mp\n","XFpx1tF0pdFNRHZqJfJLpw6iJf1kwOeH/D25IaY6cLjQE0pCuN6RJwRHTc9tPg5NNOnvo900QdQ3\n","tyENTIEwZ0erDMAdiYZ9Bttlk8opfNJvoAAkFfBYBH8QEbk/Aop8GQC3Xv1NUNN+qVJGDj/TmdZw\n","Ujxf/5mSogUVvH+4WL0EtVP/XycUiV8ssN2XvrhBFK/7rdLi/sG+1ebDSapPRPmu+SXDTcniBxn3\n","5bsv6ildyfpdaXuVOqDamxuB0AZV1Iz1Fhr25A82Duac0LF+SNj0dpp5J0Qbs6Rk3p7jsmLZY4Xo\n","N9+xwyPR6vJUp2H86YO32RvkdKaQ/8odkmNB6L3AlGn9RQujWBX2bHX1dGFAwrKepzWCFxnGVziG\n","BC8x5hXWlcTQx/XqJUZyaZK8C3Jec/fkJzQitOHI58qb4JDUjQzKEWJjIu0IOdovD2SVUgfZl50A\n","AdXnWqYKxOIXf5ActgccAv1ljVO+geqiBbu2TdO+RelPsxoK5djZDpX+o51rhDSJbOac+UHpdlXp\n","3jc2/WzrbL4D1MU4eb5YBQe4dbwrNvrUIJG2RJXiNarKsU07ueB4lx1fNrSg/NmvyVpRr7f5fRxH\n","hjoDJJSA9ySl9aqi4LPqchkcx2K/94vHWABLLOfxe9z/q2Mzg4P+iBvCd7TE34BpaFM2de5Rnbtb\n","0K85cXYFRpwwsBll5MBcDH9wsYxj6llKzzXrESvnKLX4X3oOpa9XvLzp9L9DGpUuyAvSJgWaZPd0\n","AH8momD7xg9XPHkELyQIJNsz+ysL8x12WKv0vM5Tu7iNNvNmYjYHOhxW7n+sVr1rTKHdr5hhILZR\n","TWn/dRTCyY+ePNLklXBIfDsGQ1kFRs/85ILJonqfGHHz930xKoq4WKKPRz5kHpUg6le4p7xyTQIw\n","3p+ob1E1RBVXpv5A0slxecFnOnI47kmc+w8cgC+wrscQpPVnxtDzy5gK0hYg5yC1t/nQGDf7YbMz\n","zmYU+1hI7ldO8PA0M1P3qNOFPmeslP1dOCd8wd5jaJizgFe9fV9m9bAudzLgkJzqZU6fgxN6oXVe\n","BzkT9ub4nXrDtdM/FgxY/lON9SkYw3nmFrsw37ahUPukkrsc5y3Uh/E4571OdWwSIZYGSVmVRDpy\n","VU7N+epBNECeSUo5+Aesdo9lmw2R793ojkh3bzSTcqQLXpB1y71t9jc1FcWZVC4FMPSGPd0W7Y36\n","AcPQdTZNnCSNvPjc3/6C+hY8ogh59TODbg90shf8/pQvDphKh3kvU3k1zSTCalWk6o4aZFj1XGxv\n","ERnHeqIF3MUEAtdNfBGcvciUB5uDS/P4ogghrjQROwoHlLcqWMcAZIHuwFBSDl7FdruH6qYO6mfY\n","Z/m3WfBh4NjjxeBk+avVq2Gr2xexe15PplOsSNt+Z3msfraLyOCgQ9rqkcPOMV+QGvTuhCEOPU4q\n","9VBq6U8NMvpExL7K8ZguTiscNtAXoATVAAABUUGaJGxBb/7WpVAbdvQAA4ykjCKag3K3XTEuuioI\n","dr+cocE08G9YGMli1AqaxwjMJFar8pBtQ3FZZfTViC1O7EsHRFFJXZNMugvY/Fx3Ji71abG4Mnyn\n","pPYNmYdySE8tf6xKMyGzAnrU36cFV3rlREC1ga73kCjfMNcVyw+cyz1Fa6tTWQxOhBzEdCMgIyLU\n","EsgNBEKyq8y9/S7mX+dGj3FWA6ytejeOj3OcFu3j7AHDuMBk3jzAGRiN/8SpP1rXC8Gyt/xjDubC\n","g4hxTVDz49xYMtHMF2y6ep8eiAHd4xOnxb31LmuK4NfZ/LzZuXC4LOfIsoBTAjb0/FJEPzQ5qbJ/\n","4+2xFNhIwRoY9C2fJXW81pd3UxY+7ghR4/SeSdcNKLaSlnSjXmALKZ5nODaopWPpVYXcC2VB6NOe\n","Mug6o7qQn0KvUycfELa+98eD+g+iqxgAAACMQZ5CeIKfAAvFCQn+ByJLFoABOoWTr9tyMXdSZnY5\n","zrKxi2cwBqUTx5Y2Xk6dHUPCUiHD7DqPV5QLJ36ACpHHDOZO2zA0fUwbAWQ1mYnINAmsx10RLqYu\n","pyrdsrtNoWSPHaAr8IT+vcj4YsoZ7U0YxkQCXlXf/PCwoZ8MSql4dN9VWwp7EB0RQZC+YX8AAABO\n","AZ5hdEEvABnaVQJ+6FqEsgAJqEuIgNUHMOAXfaYX8m/ti20fstot88f8TS2y5pjPqPmKo/znmSbB\n","h93l8bIsWizIV96FovBJY+I3TZIGAAAAQAGeY2pBLwAVZPq9JYukDcAH8fh+7CM/tkqlUQ7xW+ZR\n","4lc2TuVK/djt23KBKy0JTk2yUmz71UIPCPdaQSiM5tEAAACBQZpoSahBaJlMCC3//talUAt4F9oA\n","JotYnXBmuEj+hfyiaM3ezf2NU9ixX8sqTiLw+xCnVUwtRbqI8UWPiflLDKBEvF1NB+xSfIx9kafz\n","sqpEkdgO/3Om3tyGDTDuTqkouRS00xRx8LGei2dP2HkaAvPXRQovyTEcZaUg36Sp+UnPAAAAPEGe\n","hkURLBT/AAfZXm6HdxgATTDOvd7DepPYVVM0KNEI17QqG+qNN5nE2P6aRx40zdLVhuqMyCLsW4Da\n","kQAAAEwBnqV0QS8AFG32ZJK5igAnY3QX6q07lR0ODX22uaxdUOuCZ88jJ1r5dp5huBwMk72h7YSN\n","buiTZVthgkw6jfx8Z49RolsrziZhVKkxAAAArwGep2pBLwAVYYGOUNrgbgA/kJKs7DJ9gQXpVPJU\n","d1ZAXwo5rtfYP23m1TVkClbmOOnU5pl3lBrC7SZ3nbtaWva9lG17WWA1ASeauv/4nwKutcIIjeNC\n","j4JgF1Q8cykNuin9++2aZYTXQ0XNjIF6APR0YvCMgwownQ7T8jAmm3sfbk4PVDoeVC0YVIoAhxua\n","T3VEg4pg4dYzaI/BZOwrR74ZzaYnOfnTfS1VK8bPud0AAACSQZqsSahBbJlMCCv//talUAtWa5AB\n","dLSErI5m+nL99L2lboJS/tjAqmremdOiDUCc5+ElMFyln+iPmxvqPe9Ucmc+8SpUX+DRUaBwqbPm\n","BGa105vE7qwS8w/9bLuAA0lVvnaNyVMXVziHDFnMXZsS+SK1gq3J61DFWjh5YK0bfzW0AKzm2agk\n","wMi3+mqaS0a3QHAAAACXQZ7KRRUsFP8AB7CNgeX7reQALcSLz7d6hif1ulcC+7UoFSHtGt8okjfd\n","e9mnARrsZmaL7TopP0RawJM5dBhmzJH6Im6BQZoiqaaFJ/G7aWmLyeI+3POYChbLSqPglrosZxJe\n","EMSexl2rHrRWVmpVBC471C7WYXbLiq4G88DiObHDgSZUd2z/BNEdDppG48CJvvtzCmUBuQAAAEcB\n","nul0QS8AFWIcQaERFZAATT8hJAYYAksVbQKF4AkrpQyzw+rys4DB1q7TxH4m+czFuq8cqRu/AJgN\n","CoazSnKrtuxhrBjNoAAAAEABnutqQS8AFWT8xdKsgAJp8G5R6CxReFN8cBxDV7CB0eBpqUYiL7Uf\n","7qGgSVB+kf6RZVBVIFDMp4VtFhnso/xSAAAA6EGa70moQWyZTAgp//7WjLAW7/yIAEJsXDT7f1lK\n","QH/AAm0sGB04rmzS3rCHXIxqzBqb8Sqv875Uag8r+CkrARrvoBDsgFc9pfCQHs9qjLsRUK75f5a8\n","yAUqTyjxFTO4EjIqqE6jljgKCkmL+jC5RmcQlmJf8DUAtoko1vzYRh981/qHLcBH3aIBWi028yd4\n","lVrEZ1+Rqxn1J6t86/Js0fOgiECysEqRTIoPzjgZBe2KGjRCGt4ndPCPnHrj0veMBu8c80eFqc8Y\n","4+cWS7h0sgqmwhBnCAltaLqCGmO9LxvLK/Y6ztplsGEAAAA2QZ8NRRUsE/8ADnKwjURJAATPvv1P\n","5KRH+eDZGbN9JQR+Dp5nYY4mc/Nlr6pCYTXqKmOPoeLpAAAAtAGfLmpBLwAVYYIVGsgAJozt0Mnw\n","evAFakfQj3aFizw2TywU8T0qyb2+H9LJ/iausQuofUi2VBzUFfDw1vfKLfKrmXX3qTDoblJ1emxf\n","P/4n0p7Hvj7uODQgFy5o8/9We0WkzdhuwKyJtnN5uTaYlKmEx5b5XWhHnsicUCDiQN5w1GBNHX8M\n","5JbZXEc6XmG4vMi7wib7ymbfRd7n6cR1cEQDEuqQoOwfDEOjKZz0BxquFJwpWQAAARdBmzBJqEFs\n","mUwIJf/+tSqAUh3VNbU5ABOxwUhdCRaNKKJ/svu8SfbpCX+4HFx4QyxDX9ZFx4uft2U8Qt4XPBjK\n","VfYpvIGxWuf1bpeIDpYc0zLsRm/Wl58+yZuVd1WJXOHXjwc8p6eYN9hXEf0qTP15vFuMOpQvlasU\n","JOns6hj6EZig8T/xAZUATguUnYS6GQlb/oqsTQ4ym4GHNo070NF8sb8epetmfCcljv9/GuhdR9rV\n","bst2bSNTgfNgMssZsCS+Hw1BS2TcCFRz7fd9PKb5Zw/BnlBms4oa+ziKeknwBfdKrfD6ViTLL4WE\n","0zCeuMwz2qcAS6bDoqICR5aKk0yyKPJeLiJy7MB/CUIKFCbOUUE/1PeIffwAAAPybW9vdgAAAGxt\n","dmhkAAAAAAAAAAAAAAAAAAAD6AAAITQAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAB\n","AAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAAxx0cmFrAAAA\n","XHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAITQAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAA\n","AAAAAAABAAAAAAAAAAAAAAAAAABAAAAAASAAAAEgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEA\n","ACE0AABAAAABAAAAAAKUbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAABAAAACIABVxAAAAAAALWhk\n","bHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAACP21pbmYAAAAUdm1oZAAA\n","AAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAf9zdGJsAAAA\n","s3N0c2QAAAAAAAAAAQAAAKNhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAASABIABIAAAASAAA\n","AAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMWF2Y0MBZAAM/+EA\n","GGdkAAys2UEgloQAAAMABAAAAwAQPFCmWAEABmjr48siwAAAABx1dWlka2hA8l8kT8W6OaUbzwMj\n","8wAAAAAAAAAYc3R0cwAAAAAAAAABAAAAEQAAIAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAJBjdHRz\n","AAAAAAAAABAAAAABAABAAAAAAAEAAKAAAAAAAQAAQAAAAAABAAAAAAAAAAEAACAAAAAAAQAAoAAA\n","AAABAABAAAAAAAEAAAAAAAAAAQAAIAAAAAABAACgAAAAAAEAAEAAAAAAAQAAAAAAAAABAAAgAAAA\n","AAEAAIAAAAAAAgAAIAAAAAABAABAAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAEQAAAAEAAABYc3Rz\n","egAAAAAAAAAAAAAAEQAAD0kAAAFVAAAAkAAAAFIAAABEAAAAhQAAAEAAAABQAAAAswAAAJYAAACb\n","AAAASwAAAEQAAADsAAAAOgAAALgAAAEbAAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAAAFpt\n","ZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28A\n","AAAdZGF0YQAAAAEAAAAATGF2ZjU3LjgzLjEwMA==\n","\">\n","  Your browser does not support the video tag.\n","</video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"execution_count":90}]},{"cell_type":"markdown","metadata":{"id":"hhQHAGepGtVE"},"source":["### 2.2 Summary and Code Correspondance\n","\n","$\\gamma$\n","\n","<table style=\"width:20%\">\n","<thead>\n","<tr>\n","<th style=\"width:150px;font-size:20px;text-align:center;\">MDP Notation (from notes)</th>\n","<th colspan=2 style=\"width:250px;font-size:20px;text-align:center;\">GridEnv</th>\n","</tr>\n","    <tr>\n","        <td></td>\n","        <th style=\"font-size:15px;text-align:center;\">Class attribute</th>\n","        <th style=\"font-size:15px;text-align:center;\">Class method</th>\n","    </tr>\n","</thead>\n","<tbody>\n","<tr>\n","    <td style=\"text-align:left;\">$\\mathcal{S} = \\{0,\\dots,10\\}$</td>\n","    <td style=\"text-align:left;\">observation_space</td>\n","    <td style=\"text-align:left;\">get_states()</td>\n","</tr>\n","<tr>\n","    <td style=\"text-align:left;\">$\\mathcal{A} = \\{\\text{up}, \\text{down}, \\text{left}, \\text{right} \\}$</td>\n","    <td style=\"text-align:left;\">action_space</td>\n","    <td style=\"text-align:left;\">get_actions()</td>\n","</tr>\n","<tr>\n","    <td style=\"text-align:left;\">$\\mathcal{T}(s, a, s')$</td>\n","    <td style=\"text-align:left;\">state_transitions</td>\n","    <td></td>\n","</tr>\n","<!-- <tr>\n","    <td style=\"text-align:left;\">$\\mathcal{R}(s)$</td>\n","    <td style=\"text-align:left;\">immediate_rewards</td>\n","    <td></td>\n","</tr>-->\n","    <tr>\n","    <td style=\"text-align:left;\">$\\mathcal{R}(s,a)$</td>\n","    <td style=\"text-align:left;\">rewards</td>\n","    <td></td>\n","</tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"1hMDvZSgGtVE"},"source":["# 3. Iterative Policy Evaluation\n","\n","Recall the definition of the iterative policy evaluation algorithm\n","\n","![](https://raw.githubusercontent.com/Tobias-Fischer/RVSS2022/main/Reinforcement_Learning/Support/images/IterativePolicyEvaluation.png)"]},{"cell_type":"markdown","source":["Let's now compute the value function of our test policy $\\pi$\n","\n"],"metadata":{"id":"EAuWEUj8NKrN"}},{"cell_type":"markdown","source":["We consider a grid world environment with the following attributes:\n","- Discount factor $\\gamma = 0.99$ (class attribute ``gamma=0.99``)\n","- Stochastic transition matrix (class attribute ``noise=0.2``)\n","- A non-zero living cost and big rewards are obtained at terminal states (class attribute ``living_reward=-0.04``)\n","\n","Earlier, we used the helper function ``encode_policy()`` to encode our test policy. The return variable ``policy_pi`` is a dictionary of dictionaries, where each element corresponds to the probability of selecting an action $a$ at a given state $s$\n","\n","Keep in mind that each action is represented by a number. Action (Up) is represented by 0, (Down) by 1, (Left) by 2 and, finally, (Right) by 3."],"metadata":{"id":"t40A0zgbNK9Y"}},{"cell_type":"code","execution_count":79,"metadata":{"id":"JMy1n30nGtVF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643784655334,"user_tz":-660,"elapsed":392,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"98280554-b354-4498-8728-6c8d1a527163"},"outputs":[{"output_type":"stream","name":"stdout","text":["Action probabilities at state 0 are:\n","{0: 0.0, 1: 0.0, 2: 0.0, 3: 1.0}\n"]}],"source":["grid_world = GridEnv(gamma=0.99, noise=0.2, living_reward=-0.04)\n","policy_pi = encoded_test_policy\n","\n","print(\"Action probabilities at state 0 are:\\n{}\".format(dict(policy_pi[2])))"]},{"cell_type":"markdown","metadata":{"id":"5Y5WupMJGtVF"},"source":["Given the policy $\\pi$, let's now compute its state-value function using iterative policy evaluation.\n","\n","**TODO**: \n","Complete the computation of value function update for each state. We have decomposed this computation into 2 steps:\n","\n","1. Compute discounted sum of state values of all successor states: $\\text{discounted_v} = \\gamma\\sum_{s' \\in \\mathcal{S}}\\mathcal{T}(s,a,s')v(s')$ for each action\n","\n","\n","2. Compute expectation over all actions: $\\sum_{a \\in \\mathcal{A}}\\pi(a|s)(\\mathcal{R}(s,a) + \\text{discounted_v})$ \n","\n","\n","**Keep in Mind**: Correspondance between the mathematical notation and implemented code\n","\n","\n","<table style=\"width:20%\">\n","<thead>\n","<tr>\n","<th style=\"width:150px;font-size:20px;text-align:center;\">Notation in Slides</th>\n","<th colspan=2, style=\"width:450px;font-size:20px;text-align:center;\">Code</th>\n","</tr>\n","    <tr>\n","        <td></td>\n","        <th style=\"font-size:15px;text-align:left;\">Variable/Attribute</th>\n","        <th style=\"font-size:15px;text-align:left;\">Type</th>\n","    </tr>\n","</thead>\n","<tbody>\n","<tr>\n","    <td style=\"text-align:left;\">$\\gamma$</td>\n","    <td style=\"text-align:left;font-size:15px;\">grid_world.gamma</td>\n","    <td>float</td>\n","</tr>\n","<tr>\n","    <td style=\"text-align:left;\">$\\mathcal{T}(s, a, s')$</td>\n","    <td style=\"text-align:left;font-size:15px;\">grid_world.state_transitions[idx_s, idx_a, idx_s]</td>\n","    <td>numpy 3d-array</td>\n","</tr>\n","<tr>\n","    <td style=\"text-align:left;\">$\\mathcal{R}(s, a)$</td>\n","    <td style=\"text-align:left;font-size:15px;\">grid_world.rewards[idx_s, idx_a]</td>\n","    <td>numpy 2d-array</td>\n","</tr>\n","<tr>\n","    <td style=\"text-align:left;\">$\\pi(a|s)$</td>\n","    <td style=\"text-align:left;font-size:15px;\">policy_pi[idx_s][idx_a]</td>\n","    <td>dict of dict</td>\n","</tr>\n","<tr>\n","    <td style=\"text-align:left;\">$v_\\pi(s)$</td>\n","    <td style=\"text-align:left;font-size:15px;\">v[idx_s]</td>\n","    <td>dict</td>\n","</tr>\n","</table>"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"IVu1D1gRGtVF","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1643785603776,"user_tz":-660,"elapsed":350,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"193fe6a1-c9e2-4506-c25e-073a630c6f42"},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0}\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["def policy_evaluation(grid_env, policy, plot=False, threshold=0.00001):\n","    \n","    \"\"\"\n","    This function computes the value function for a policy pi in a given environment grid_env.\n","    \n","    :param grid_env (GridEnv): MDP environment\n","    :param policy (dict - stochastic form): Policy being evaluated\n","    :return: (dict) State-values for all non-terminal states\n","    \"\"\"\n","        \n","    # Obtain list of all states in environment\n","    v = {s: 0.0 for s in grid_env.get_states()}\n","    theta = threshold\n","    delta = 1000\n","\n","    while delta > theta:\n","        delta = 0.0\n","        # For all states\n","        for s in v.keys():\n","\n","            old_v = v[s]\n","            new_v = 0\n","\n","            # For all actions\n","            for a in grid_env.get_actions():\n","                discounted_v = 0\n","\n","                # For all states that are reachable from s with action a\n","                for s_next in grid_env.get_states():\n","                    # TODO 1: Compute discounted sum of state values for all successor states\n","                    discounted_v += 0\n","\n","                    \n","                # TODO 2: Compute expectation over all actions\n","                new_v += 0\n","\n","            v[s] = new_v\n","            delta = max(delta, np.abs(old_v - new_v))\n","\n","    if plot:\n","        plot_value_function(grid_env, v)\n","        \n","    return v\n","        \n","        \n","# Call the policy evalution function\n","v = policy_evaluation(grid_world, policy_pi, plot=True)\n","print(v)"]},{"cell_type":"markdown","metadata":{"id":"xtO7Uk-nGtVF"},"source":["# 4. Policy Iteration"]},{"cell_type":"markdown","metadata":{"id":"RQUzao_mGtVG"},"source":["Recall the definition of the policy iteration algorithm\n","\n","![](https://raw.githubusercontent.com/Tobias-Fischer/RVSS2022/main/Reinforcement_Learning/Support/images/PolicyIteration.png)"]},{"cell_type":"markdown","source":["Starting with a random policy, let's find the optimal policy for a grid world environment with attributes:\n","\n","We consider a grid world environment with the following attributes:\n","- Discount factor $\\gamma = 0.99$ (class attribute ``gamma=0.99``)\n","- Stochastic transition matrix (class attribute ``noise=0.2``)\n","- Rewards are only obtained at terminal states (class attribute ``living_reward=-0.04``)\n","\n","We will first define some helper methods:\n","- ``one_step_look_ahead(grid_env, state, value_function)``, this method computes the action-value function for a state $s$ given the state-value function $v$. This corresponds to $\\mathcal{R}(s,a) + \\gamma\\sum_{s' \\in \\mathcal{S}}\\mathcal{T}(s,a,s')v_\\pi(s')\\, \\forall \\, a \\in \\mathcal{A}$\n","\n","\n","- ``update_policy(grid_world, policy, value_function)``, this method updates the current policy $\\pi$ given the state-value function $v$ by taking the action $a$ with the highest action-value. \n","\n","\n","- ``define_random_policy(grid_env)`` in script ``helper.py``, this method generates a random policy for environment ``grid_env``"],"metadata":{"id":"GtDsTrEjNtsl"}},{"cell_type":"code","execution_count":81,"metadata":{"id":"0lgB6hMuGtVG","executionInfo":{"status":"ok","timestamp":1643784675108,"user_tz":-660,"elapsed":285,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}}},"outputs":[],"source":["def one_step_look_ahead(grid_env, state, value_function):\n","    \"\"\"\n","     Compute the action-value function for a state $s$ given the state-value function $v$.\n","     \n","     :param grid_env (GridEnv): MDP environment\n","     :param state (int): state for which we are looking one action ahead\n","     :param value_function (dict): state-value function associated to a given policy py\n","     \n","     :return: (np.array) Action-value function for all actions available at state s\n","    \"\"\"\n","    action_values = []\n","    \n","    for action in grid_env.get_actions():\n","        discounted_value = 0\n","        for s_next in grid_env.get_states():\n","             discounted_value += grid_env.state_transitions[state, action, s_next] * value_function[s_next]\n","        \n","        q_a = grid_env.rewards[state, action] + grid_env.gamma * discounted_value\n","        action_values.append(q_a)\n","    \n","    return np.array(action_values)"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"FsnGxnvtGtVG","executionInfo":{"status":"ok","timestamp":1643784677815,"user_tz":-660,"elapsed":309,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}}},"outputs":[],"source":["def update_policy(grid_env, cur_policy, value_function):\n","    \"\"\"\n","     Update a given policy based on a given value_function\n","     \n","     :param grid_env (GridEnv): MDP environment\n","     :param cur_policy (matrix form): Policy to update\n","     :param value_function: state-value function associated to a policy cur_policy\n","     \n","     :return: (dict) Updated policy\n","    \"\"\"\n","    \n","    states = grid_env.get_states(exclude_terminal=True)\n","    \n","    for s in states:\n","        # Obtain state-action values for state s using the helper function one_step_look_ahead\n","        action_values = one_step_look_ahead(grid_env, s, value_function)\n","        \n","        # Find (row, col) coordinates of cell with index s\n","        row, col = np.argwhere(grid_env.grid == s)[0]\n","        \n","        cur_policy[row, col] = np.argmax(action_values)\n","        \n","    return cur_policy"]},{"cell_type":"markdown","metadata":{"id":"-4WkoHtbGtVG"},"source":["Let's now define the policy iteration core algorithm.\n","\n","**TODO**: Complete the main steps of the policy iteration algoritm.\n","- Use ``policy_evaluation(.)`` to compute the state-value function of a given policy\n","- Use ``update_policy(.)`` to obtain an updated policy"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"-1XJB-z5GtVG","executionInfo":{"status":"ok","timestamp":1643784973429,"user_tz":-660,"elapsed":302,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}}},"outputs":[],"source":["def policy_iteration(grid_env, policy, plot=False):\n","    \"\"\"\n","    This function iteratively updates a given policy pi for a given environment grid_env until convergence to optimal policy\n","    \n","    :param grid_env (GridEnv): MDP environment\n","    :param policy (matrix from): Deteministic policy being updated\n","    :return: (dict) State-values for all non-terminal states\n","    \"\"\"\n","    prev_policy = np.zeros(policy.shape)\n","    \n","    while not np.all(np.equal(prev_policy, policy)):\n","        \n","        # Encode policy. This policy representation is needed for policy evaluation\n","        encoded_policy = encode_policy(grid_env, policy)\n","        # Set prev_policy to current policy\n","        prev_policy = policy.copy()\n","        \n","        #TODO: Complete the remaining steps\n","        # 1. Evaluate the given policy (policy_evaluation expects an mdp and the enconded_policy as arguments)\n","        \n","        # 2. Update policy using helper function update_policy\n","        \n","        \n","    if plot:\n","        plot_policy(grid_env, policy)\n","    \n","    return policy"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"MFrBvPSsGtVH","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1643784980949,"user_tz":-660,"elapsed":990,"user":{"displayName":"Dana Kulic","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuEqV-iV8rSpDHO2jxqd7MnkIdtPYbssZsmpzQCw=s64","userId":"07057531030310424990"}},"outputId":"aaf32f24-bd15-45e4-d1f4-b6b916f23c5d"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# Create a grid world mdp\n","grid_world = GridEnv(gamma=0.99, noise=0.2, living_reward=-0.04)\n","\n","# Generate an initial random policy\n","initial_policy = define_random_policy(grid_world)\n","plot_policy(grid_world,initial_policy)\n","\n","# Compute optimal policy using policy iteration\n","optimal_policy = policy_iteration(grid_world, initial_policy, plot=True)"]}],"metadata":{"kernelspec":{"display_name":"IntelligentRobotics","language":"python","name":"intelligentrobotics"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"IntroRLv2.ipynb","provenance":[{"file_id":"https://github.com/Tobias-Fischer/RVSS2022/blob/main/Reinforcement_Learning/Session%201%20-%20IntroRL.ipynb","timestamp":1643683024622}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}