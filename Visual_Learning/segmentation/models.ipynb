{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchvision.models.resnet import model_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the general network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(NetModel, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # Define loss function here:\n",
    "    def get_criterion(self):\n",
    "        return CrossEntropyLoss()\n",
    "\n",
    "    # Define optimiser here\n",
    "    def get_optimiser(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.args.lr,\n",
    "                                weight_decay=self.args.weight_decay)\n",
    "\n",
    "    # Learning rate is reduced to 'lr*gamma' every 'step_size' of epochs\n",
    "    def get_lr_scheduler(self, optimiser):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            This function by default returns None\n",
    "        \"\"\"\n",
    "        return lr_scheduler.StepLR(\n",
    "            optimiser, gamma=self.args.scheduler_gamma,\n",
    "            step_size=self.args.scheduler_step)\n",
    "\n",
    "    # A training step, do not need modifications\n",
    "    def step(self, batch):\n",
    "        image, label = batch\n",
    "        pred = self.forward(image)\n",
    "        loss = self.criterion(pred, label)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Resnet 18 Segmentation Baseline Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res18Baseline(NetModel):\n",
    "    def __init__(self, args):\n",
    "        super(Res18Baseline, self).__init__(args)\n",
    "        # Load pre-trained lyrn_backend\n",
    "        res18 = models.resnet18(pretrained=False)\n",
    "        # with torch.no_grad():\n",
    "        self.res18_backbone = nn.Sequential(*list(\n",
    "            res18.children())[:-6])\n",
    "        self.conv2_x = nn.Sequential(*list(\n",
    "            res18.children())[-6:-5])\n",
    "        self.conv3_x = nn.Sequential(*list(\n",
    "            res18.children())[-5:-4])\n",
    "        self.conv4_x = nn.Sequential(*list(\n",
    "            res18.children())[-4:-3])\n",
    "        self.conv5_x = nn.Sequential(*list(\n",
    "            res18.children())[-3:-2])\n",
    "\n",
    "        # Reduces the number of channels of resnet output\n",
    "        self.top_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # backgound is considered as one additional class\n",
    "        #   with label '0' by default\n",
    "        self.segmentation_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, self.args.n_classes + 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        # Define loss function here\n",
    "        self.criterion = self.get_criterion()\n",
    "\n",
    "    def forward(self, img):\n",
    "        # Encoder\n",
    "        c1 = self.res18_backbone(img)\n",
    "        c2 = self.conv2_x(c1)  # feature map spaticl dim 48 x 64\n",
    "        c3 = self.conv3_x(c2)  # feature map spaticl dim 24 x 32\n",
    "        c4 = self.conv4_x(c3)  # feature map spaticl dim 12 x 16\n",
    "        c5 = self.conv5_x(c4)  # feature map spaticl dim 6 x 8\n",
    "        # Decoder\n",
    "        out = self.top_conv(c5)\n",
    "        out = nn.UpsamplingBilinear2d(scale_factor=16)(out)\n",
    "        out = self.segmentation_conv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Resnet 18 segmentation with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res18Skip(NetModel):\n",
    "    def __init__(self, args):\n",
    "        super(Res18Skip, self).__init__(args)\n",
    "        res18 = models.resnet18(pretrained=False)\n",
    "        self.res18_backbone = nn.Sequential(*list(\n",
    "            res18.children())[:-6])\n",
    "        self.conv2_x = nn.Sequential(*list(\n",
    "            res18.children())[-6:-5])\n",
    "        self.conv3_x = nn.Sequential(*list(\n",
    "            res18.children())[-5:-4])\n",
    "        self.conv4_x = nn.Sequential(*list(\n",
    "            res18.children())[-4:-3])\n",
    "        self.conv5_x = nn.Sequential(*list(\n",
    "            res18.children())[-3:-2])\n",
    "\n",
    "        self.top_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.lateral_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.lateral_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.lateral_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # background is considered as one additional class\n",
    "        #   with label '0' by default\n",
    "        self.segmentation_conv = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, self.args.n_classes + 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.criterion = self.get_criterion()\n",
    "\n",
    "    def upsample_add(self, low_res_map, high_res_map):\n",
    "        upsampled_map = nn.UpsamplingBilinear2d(scale_factor=2)(low_res_map)\n",
    "        return upsampled_map + high_res_map\n",
    "\n",
    "    def forward(self, img):\n",
    "        # Encoder\n",
    "        c1 = self.res18_backbone(img)\n",
    "        c2 = self.conv2_x(c1)  # 48 x 64\n",
    "        c3 = self.conv3_x(c2)  # 24 x 32\n",
    "        c4 = self.conv4_x(c3)  # 12 x 16\n",
    "        c5 = self.conv5_x(c4)  # 6 x 8\n",
    "        # Decoder\n",
    "        p5 = self.top_conv(c5)  # 6 x 8\n",
    "        p4 = self.upsample_add(p5, self.lateral_conv1(c4))  # 12 x 16\n",
    "        p3 = self.upsample_add(p4, self.lateral_conv2(c3))  # 24 x 32\n",
    "        p2 = self.upsample_add(p3, self.lateral_conv3(c2))  # 48 x 64\n",
    "        out = nn.UpsamplingBilinear2d(scale_factor=2)(p2)\n",
    "        out = self.segmentation_conv(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
