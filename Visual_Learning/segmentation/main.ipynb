{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# TODO: change github access token\n",
    "username = 'Tobias-Fischer'\n",
    "repository = 'RVSS2022'\n",
    "git_token = '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'\n",
    "\n",
    "%cd /content/drive/MyDrive/\n",
    "if not os.path.exists('RVSS2022'):\n",
    "  !git clone https://{git_token}@github.com/{username}/{repository}\n",
    "else:\n",
    "  %cd /content/drive/MyDrive/RVSS2022\n",
    "  !git pull\n",
    "%cd /content/drive/MyDrive/RVSS2022/Visual_Learning/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the module 'secure_write' could not be imported. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details.\n",
      "<a href='https://aka.ms/kernelFailuresModuleImportErr'>Learn more</a>"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from segmenter import Segmenter\n",
    "import numpy as np\n",
    "\n",
    "import utils.cmd_printer as cmd_printer\n",
    "from models import Res18Baseline\n",
    "from models import Res18Skip\n",
    "from trainer import Trainer\n",
    "from args import args\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Face Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import FaceIMDB\n",
    "\n",
    "# args\n",
    "args.dataset_dir = 'datasets/faces'\n",
    "args.weights_dir = 'weights/face_baseline'\n",
    "args.n_classes = 2\n",
    "args.batch_size = 32\n",
    "# print args\n",
    "cmd_printer.divider(text=\"Hyper-parameters\", line_max=60)\n",
    "for arg in vars(args):\n",
    "    print(f\"   {arg}: {getattr(args, arg)}\")\n",
    "cmd_printer.divider(line_max=60)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=FaceIMDB(args.dataset_dir, mode='train'),\n",
    "                          batch_size=args.batch_size, shuffle=True,\n",
    "                          num_workers=4, drop_last=True)\n",
    "\n",
    "eval_loader = DataLoader(dataset=FaceIMDB(args.dataset_dir, mode='eval'),\n",
    "                         batch_size=args.batch_size, shuffle=False,\n",
    "                         num_workers=4, drop_last=False)\n",
    "   \n",
    "if args.model == 'res18_baseline':\n",
    "    model = Res18Baseline(args)\n",
    "elif args.model == 'res18_skip':\n",
    "    model = Res18Skip(args)\n",
    "trainer = Trainer(args)\n",
    "trainer.fit(model, train_loader, eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Face Segmentation\n",
    "### 'ckpt' represents checkpoint.\n",
    "\n",
    "You can set `ckpt = ''` to test if your network architecture is implemented correctly.\n",
    "\n",
    "Later on, you can set `ckpt = <path_to_weight_file>` to inspect the network outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = ''\n",
    "ckpt = 'weights/face_baseline/model.best.pth'\n",
    "model = 'res18_baseline'\n",
    "# ckpt = 'res18_skip_weights.pth'\n",
    "# model = 'res18_skip'\n",
    "segmenter = Segmenter(ckpt, use_gpu=False, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"test_images/faces\"\n",
    "pred_dir = os.path.join(test_dir, model+'_output')\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "all_test_images = [file for file in os.listdir(\n",
    "    test_dir) if file.endswith('.jpg')]\n",
    "for image_name in all_test_images:\n",
    "    np_img = np.array(Image.open(os.path.join(test_dir, image_name)))\n",
    "    pred, colour_map = segmenter.segment_single_image(\n",
    "        np_img, resize_to=(256, 256), labels=['hair', 'face', 'bg'])\n",
    "    title = [\"Input\", \"Prediction\"]\n",
    "    pics = [np_img, colour_map]\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axs[0].imshow(pics[0], interpolation='nearest')\n",
    "    axs[0].set_title(title[0])\n",
    "    axs[1].imshow(pics[1], interpolation='nearest')\n",
    "    axs[1].set_title(title[1])\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    path = os.path.join(pred_dir, image_name)\n",
    "    plt.savefig(os.path.join(pred_dir, image_name[:-4]+'.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Fruit Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imdb import FruitIMDB\n",
    "\n",
    "# # args\n",
    "# args.dataset_dir = 'datasets/fruit'\n",
    "# args.weights_dir = 'weights/fruit_baseline'\n",
    "# args.n_classes = 4\n",
    "# args.batch_size = 64\n",
    "# # print args\n",
    "# cmd_printer.divider(text=\"Hyper-parameters\", line_max=60)\n",
    "# for arg in vars(args):\n",
    "#     print(f\"   {arg}: {getattr(args, arg)}\")\n",
    "# cmd_printer.divider(line_max=60)\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(dataset=FruitIMDB(args.dataset_dir, mode='train'),\n",
    "#                           batch_size=args.batch_size, shuffle=True,\n",
    "#                           num_workers=4, drop_last=True)\n",
    "\n",
    "# eval_loader = DataLoader(dataset=FruitIMDB(args.dataset_dir, mode='eval'),\n",
    "#                          batch_size=args.batch_size, shuffle=False,\n",
    "#                          num_workers=4, drop_last=False)\n",
    "\n",
    "# if args.model == 'res18_baseline':\n",
    "#     model = Res18Baseline(args)\n",
    "# elif args.model == 'res18_skip':\n",
    "#     model = Res18Skip(args)\n",
    "# trainer = Trainer(args)\n",
    "# trainer.fit(model, train_loader, eval_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6bca7b956aba6ad70b81e5790d180355329715e62b4bdc0f2e18c537f42a8c7e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('rvss21': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
