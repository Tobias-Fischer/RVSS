{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"30\">Camera and image motion</font></div></td>\n",
    "    <td><img src=\"https://github.com/Tobias-Fischer/RVSS2022/blob/main/Robotic_Vision/common/RVSS-logo.png?raw=1\" width=\"400\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from machinevisiontoolbox import CentralCamera\n",
    "from spatialmath import SE3\n",
    "import scipy.linalg as lin\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(linewidth=120, formatter={'float': lambda x: f\"{x:8.4g}\" if abs(x) > 1e-10 else f\"{0:8.4g}\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Relationship between camera and image-plane motion\n",
    "Instantiate a projective camera object, centred at the origin and viewing parallel to the world frame z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name: default perspective camera [CentralCamera]\n",
      "     pixel size: 1e-05 x 1e-05\n",
      "     image size: 1000 x 1000\n",
      "           pose: t = 0, 0, 0; rpy/yxz = 0°, 0°, 0°\n",
      "   principal pt: [     500      500]\n",
      "   focal length: [   0.008    0.008]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera = CentralCamera.Default()\n",
    "print(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a point in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [1, 1, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will project it to the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     660],\n",
       "       [     660]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = camera.project_point(P)\n",
    "p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we displace the camera slightly (distance `d`) in the x-direction the pixel coordinates will become"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     644],\n",
       "       [     660]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 0.1\n",
    "px = camera.project_point(P, pose=SE3([d, 0, 0]))\n",
    "px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the camera coordinate conventions of RVC2 Fig. 11.5, the camera has moved to the right so the image point has moved to the left. The sensitivity of image motion to camera motion is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -160],\n",
       "       [       0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( px - p0) / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is an approximation to the partial derivative $\\partial p / \\partial x$. It shows that 1 m of camera motion would lead to −160 pixel of feature motion in the u-direction. \n",
    "\n",
    "We can repeat this for z-axis translation, ie. moving the camera forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   32.65],\n",
       "       [   32.65]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( camera.project_point(P, pose=SE3([0, 0, d])) - p0) / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is an approximation to the partial derivative $\\partial p / \\partial z$, and  shows equal motion in the u- and v-directions\n",
    "\n",
    "We can also rotate the camera about the x-axis, equivalent to pitching the camera upwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   40.96],\n",
       "       [   851.9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = camera.project_point(P, pose=SE3.Rx(d))\n",
    "( px - p0) / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is predominantly motion down in the image, remember the v-axis points down in the image. the image motion is predominantly in the v-direction. It is clear that camera motion along and about the different degrees of freedom in SE(3) causes quite different motion of image points.\n",
    "\n",
    "## Things to try on your own\n",
    "1. use a smaller value of `d` when computing the numerical approximation to the Jacobian\n",
    "\n",
    "# Image Jacobian\n",
    "\n",
    "Consider the camera as a function \n",
    "\\begin{equation}\n",
    "p = {\\cal P}(P, \\mathbf{K}, \\xi)\n",
    "\\end{equation}\n",
    "where $p \\in \\mathbb{R}^2$ is the image-plane point, $P \\in \\mathbb{R}^3$ is the world point, $\\mathbf{K} \\in \\mathbb{R}^{3 \\times 3}$ is the camera intrinsics and $\\xi \\in SE(3)$ is the camera pose. Its derivative with respect to time is\n",
    "\\begin{equation}\n",
    "\\dot{p} = \\mathbf{J}_p(P, \\mathbf{K}, \\xi) \\nu\n",
    "\\end{equation}\n",
    "where $\\nu = (v_x, v_y, v_z, \\omega_x, \\omega_y, \\omega_z) \\in \\mathbb{R}^6$ is the velocity of the camera -- the spatial velocity.\n",
    "\n",
    "$\\mathbf{J}_p$ is a Jacobian-like object, but because we have taken the derivative with respect to a pose $\\xi \\in SE(3)$ rather than a vector it is technically called an _interaction matrix_. However in the visual servoing world it is more commonly called an _image Jacobian_ or a _feature sensitivity matrix_.\n",
    "\n",
    "The Toolbox CentralCamera class provides the method visjac_p to compute the image Jacobian and for the example above it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -160,        0,     34.4,    36.98,     -837,      172],\n",
       "       [       0,     -160,     34.4,      837,   -36.98,     -172]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = camera.visjac_p( (672, 672), 5)\n",
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column gives the image-plane velocity for the corresponding component of camera velocity, ie. the first column corresponds to camera x-axis motion, the second column corresponds to camera x-axis motion and the last column correpsonds to camera z-axis rotation.  In Out[6] we computed a numerical approximation to the first column,  Out[7] an approximation to the third column, and Out[8] is an approximation to the fourth column.\n",
    "\n",
    "If the camera is moving at 1m/s in the x-axis direction the velocity at the pixel will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    -160,        0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ [1, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in units of pixel/s.\n",
    "\n",
    "If the velocity was 1rad/s around the z-axis the velocity at the pixel will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     172,     -172])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ [0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if the camera velocity was 1m/s in the x-axis direction *and* 1rad/s in around the z-axis the velocity at the pixel will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      12,     -172])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ [1, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical flow fields\n",
    "\n",
    "We just computed the image Jacobian for a single point close to the centre of the image plane.  Imagine now that we compute it for a grid over the image plane and then see how the image-plane velocity at each point varies with camera veloicty.\n",
    "\n",
    "The example below provides you with a slider for each component of camera velocity.  As you adjust them the corresponding optical flow field is displayed. Have a play and try to understand what this is showing you.  What happens if you motion in several dimensions of the camera velocity space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97b5e6996c54d759441c56e5f7a6ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='X:', max=1.0, min=-1.0), FloatSlider(value=0.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "camera = CentralCamera.Default() # create camera object\n",
    "\n",
    "\n",
    "@widgets.interact\n",
    "def animate( x =  widgets.FloatSlider(value=0, description='X:',  min=-1, max=1),\n",
    "             y =  widgets.FloatSlider(value=0,   description='Y:',  min=-1, max=1),\n",
    "             z =  widgets.FloatSlider(value=0,   description='Z:',  min=-1, max=1),\n",
    "             rx = widgets.FloatSlider(value=0,   description='rX:', min=-1, max=1),\n",
    "             ry = widgets.FloatSlider(value=0,   description='rY:', min=-1, max=1),\n",
    "             rz = widgets.FloatSlider(value=0,   description='rZ:', min=-1, max=1) ):\n",
    "\n",
    "    Z = 2  # distance to the grid of points\n",
    "    vel = [x, y, z, rx, ry, rz]  # camera velocity from sliders, as a column vector\n",
    "    \n",
    "    # setup the plot window, fixed scale, unity aspect ratio, grid lines on\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = plt.gca()\n",
    "    plt.grid(True)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_facecolor('yellow')\n",
    "    plt.xlabel('u (pixels)')\n",
    "    plt.ylabel('v (pixels)')\n",
    "    plt.title('Velocity on camera image plane')\n",
    "    plt.xlim(0, 1000)\n",
    "    ax.set_ylim(1000, 0)  # inverted y-axis\n",
    "\n",
    "\n",
    "    # compute optical flow over a grid of points\n",
    "    a = np.arange(-1000, 1000, 50)  # set of flow points\n",
    "\n",
    "    [U, V] = np.meshgrid(a, a, indexing='ij')\n",
    "    du = np.empty(U.shape)\n",
    "    dv = np.empty(U.shape)\n",
    "    \n",
    "    for i in range(U.shape[1]):\n",
    "        for j in range(U.shape[0]):\n",
    "            pdot = camera.visjac_p( ([U[i,j], V[i,j]]), Z) @ vel\n",
    "            du[i,j] = pdot[0]\n",
    "            dv[i,j] = pdot[1]\n",
    "\n",
    "    # plot the flow vectors\n",
    "    #  -dv is to overcome a bug with quiver and flipped vertical axis\n",
    "    plt.quiver(U, V, du, -dv, scale=8000)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try on your own\n",
    "1. Change the camera to a 4mm focal length, and see the change in the shape of the optical flow fields for rotation about the x- and y-axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imperceptible motion\n",
    "Define a point in the world and compute its image Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [0, 0, 5]\n",
    "p = camera.project_point(P)\n",
    "J = camera.visjac_p( p, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian is $2 \\times 6$ which means it has a nullity of 4, that is, there are four possible velocities that will cause zero image plane motion, as will any linear combination of these velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = lin.null_space(J)\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly verify this is the case for the first column which is a camera velocity of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        0,        1,        0,        0,        0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the resulting image-plane velocity is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J @ N[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is effectively zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiguous motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    -160,        0,       32,       32,     -832,      160],\n",
       "       [       0,     -160,       32,      832,      -32,     -160]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = [1, 1, 5]\n",
    "p = camera.project_point(P)\n",
    "J = camera.visjac_p( p, 5)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceae060e916e4633b2a7678a6605cdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=8.0, description='f (mm): ', min=1.0), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, floatmode='maxprec')\n",
    "np.set_printoptions(suppress=True)\n",
    "@widgets.interact\n",
    "def animate( f =  widgets.FloatSlider(value=8, description='f (mm): ',  min=1, max=100) ):\n",
    "    camera = CentralCamera.Default(f=f*1e-3) # create camera object\n",
    "    p = camera.project_point(P)\n",
    "    J = camera.visjac_p( p, 5)\n",
    "    print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
